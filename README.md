# ğŸ§  NMHG: Neural Multi-Hop Generator  
### *A Scalable Architecture for Multi-Hop Retrieval, Evidence Verification, and Generative Reasoning*

This repository implements **NMHG**, a full-stack multi-hop retrieval & reasoning system composed of:

1. **A Pinecone-backed scalable retrieval engine** using  
   - multilingual-e5-large embeddings  
   - SimHash-guided server-side filtering  
   - multimodal (text + synthetic images) ingestion  
   - real-dataset evaluation (HotpotQA, MuSiQue, M-BEIR)

2. **A local architectural NMHG engine** demonstrating  
   - synthetic multimodal graph  
   - hop planner (beam search)  
   - SimHash-guided pruning  
   - evidence verifier  
   - evidence-constrained generator  
   - multi-hop QA chain evaluation  

Together, these modules deliver a complete end-to-end system aligned with all mid-report and final project requirements.

---

# ğŸ“ Repository Structure
```
.
â”œâ”€â”€ z1.py   # Pinecone ingestion: HotpotQA + MuSiQue + synthetic multimodal nodes
â”œâ”€â”€ z2.py   # Live retrieval UI (baseline vs NMHG filter) using Pinecone indexes
â”œâ”€â”€ z3.py   # M-BEIR benchmark: Recall, MRR, NDCG, pruning rate, latency, speedup
â”œâ”€â”€ z4.py   # Local NMHG graph: embeddings, SimHash, edges, hop planner, verifier
â”œâ”€â”€ z5.py   # End-to-end local NMHG multi-hop reasoning + generator + baselines
â””â”€â”€ README.md   # (this file)
```
---

# ğŸš€ System Overview

NMHG is organized into **two pillars**, each serving a distinct purpose:

---

## ğŸ§± Pillar A â€” Real-World Scalable Retrieval (z1â€“z2â€“z3)

These components demonstrate NMHGâ€™s scalability on real datasets using Pinecone.

### âœ” Datasets:
- **HotpotQA (validation split)**
- **MuSiQue (validation split)**
- **M-BEIR (query split)**

### âœ” Features:
- Vector ingestion into Pinecone (text + synthetic images)
- SimHash block-based metadata for filtering
- Real retrieval comparisons:
  - baseline dense retrieval  
  - NMHG filtered retrieval  
- Speedup measurement
- Full evaluation metrics on M-BEIR:
  - Recall@10  
  - MRR@10  
  - Precision@10  
  - NDCG@10  
  - Latency  
  - Pruning ratio  
  - False-negative rate  
  - Speedup factor  

These scripts provide the **quantitative** and **scalability** results for the project.

---

## ğŸ§± Pillar B â€” NMHG Reasoning Engine (z4â€“z5)

These files demonstrate the **architectural behavior** of NMHG using a synthetic multimodal world.

### âœ” Features:
- Synthetic graph: ~1500 text nodes + ~200 projected image nodes
- E5 text embeddings + CLIP image embeddings (projected to 1024-dim)
- Cosine similarity edges + caption-image edges
- SimHash-based pruning structure
- Hop planner using beam search
- Evidence verifier scoring chains
- Synthetic QA dataset with gold chains
- Evidence-only generator
- Baselines:
  - Dense kNN retrieval (NumPy)
  - Query reformulation baseline

Provides qualitative examples and demonstrates **multi-hop chain reasoning**.

---

# ğŸ§© Detailed File Descriptions

## ğŸŸ¦ z1.py â€” Pinecone Ingestion Pipeline

This script handles:

- Loading HotpotQA + MuSiQue
- Constructing text passages
- Generating 5000 synthetic â€œimage nodesâ€
- Embedding text using **multilingual-e5-large**
- Embedding images using **CLIP ViT-B/32** then projecting to 1024-dim
- Computing 64-bit SimHash blocks for each vector
- Upserting all data into Pinecone indexes:
  - `nmhg-hotpotqa`
  - `nmhg-musique`

### Run:
```bash
python z1.py
```

## ğŸŸ© z2.py â€” Live Pinecone Retrieval UI

A terminal UI for interactively comparing:
- baseline vector search (Pinecone dense)
- NMHG SimHash-filtered search

For each query, it prints:
- baseline latency
- NMHG latency
- speedup factor
- retrieved documents

### Run:
```bash
python z2.py
```

## ğŸŸ¥ z3.py â€” M-BEIR Retrieval Benchmark (Local)

Provides all retrieval metrics needed for the final report.

Computes:

### ğŸ”¹ Retrieval Quality
- Recall@10
- MRR@10
- Precision@10
- NDCG@10

### ğŸ”¹ Filtering Performance
- Pruning ratio
- False-negative rate

### ğŸ”¹ Latency
- NMHG retrieval latency
- Dense retrieval latency
- Speedup factor

### Dataset:
- M-BEIR (query split), streaming evaluation

Run:
```bash
python z3.py
```

## ğŸŸ¨ z4.py â€” NMHG Graph Constructor

Builds the entire local NMHG architecture:
- Random multimodal graph
- Topic-aligned text nodes
- Projected CLIP image nodes
- Cosine similarity edges
- Caption-image edges
- 64-bit SimHash hashing
- Hop Planner (beam search)
- Evidence Verifier
- Synthetic QA dataset creation

This is the core architectural implementation.

## ğŸŸ§ z5.py â€” Local NMHG Multi-Hop Reasoning Engine

Runs the full NMHG pipeline:

### âœ” For each synthetic QA pair:
- Encodes question using E5
- Computes SimHash for pruning
- Executes hop planner
- Retrieves multi-hop chain
- Verifies chain quality
- Generates answer using evidence only
- Compares against baselines
- Prints example chains and generated answers

### âœ” Computes:
- Recall@K
- Chain coverage
- Intermediate precision
- Avg nodes explored per hop

Run:
```bash
python z5.py
```
ğŸ“Š Evaluation Summary

## Local Evaluation (M-BEIR, z3)

This gives the intrinsic retrieval performance of NMHG:
- Recall@10
- Precision@10
- MRR@10
- NDCG@10
- Latency (dense vs NMHG)
- Speedup factor
- Pruning ratio
- False-negative rate

These metrics appear in the â€œResults: Retrieval Qualityâ€ section of the final report.


## Pinecone Evaluation (z2)

This gives the real-world scalability performance:
- Latency of baseline search
- Latency of NMHG filtered search
- Speedup factor
- Real examples from HotpotQA / MuSiQue

These results belong in the â€œResults: Efficiency & Scalabilityâ€ section.


## Architectural Demonstration (z4â€“z5)

This gives the qualitative & architectural behavior:
- Synthetic QA chains
- Retrieved multi-hop paths
- Evidence-verifier scoring
- Evidence-constrained answer generation
- Baseline comparisons
- Efficiency (nodes explored per hop)

These belong in the â€œMethodology & Architectureâ€ section.


# ğŸ›  Installation & Dependencies

Install Python packages:
```bash
pip install sentence-transformers
pip install open_clip_torch
pip install numpy
pip install pinecone-client
pip install datasets
pip install colorama
pip install tqdm
```

# ğŸ“ Citing Datasets & Models

This project uses:
- HotpotQA
- MuSiQue
- M-BEIR
- E5-Large multilingual
- CLIP ViT-B/32


# ğŸ Conclusion

This repository delivers a complete end-to-end NMHG system including:
- Scalable vector retrieval
- SimHash-based filtering
- Multi-hop reasoning
- Evidence verification
- Synthetic knowledge graph
- Local + cloud evaluation
- Baselines & qualitative samples
- Full retrieval metrics
